{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa15d915-ccfd-4aab-9cea-5fdfd4dd1882",
   "metadata": {
    "id": "o8L28axZ4NVj",
    "tags": []
   },
   "source": [
    "# Initial Structure to Relaxed Energy (IS2RE) <a name=\"is2re\"></a>\n",
    "The IS2RE task predicts the relaxed energy (energy of the relaxed state) given the initial state of a system. One approach to this is by training a regression model mapping the initial structure to the relaxed energy. We call this the *direct* approach to the IS2RE task. \n",
    "\n",
    "An alternative is to perform a structure relaxation using an S2EF model to obtain the relaxed state and compute the energy of that state (see the IS2RS task below for details about relaxation).\n",
    "\n",
    "### Steps for training an IS2RE model\n",
    "1) Define or load a configuration (config), which includes the following\n",
    "* task\n",
    "* model\n",
    "* optimizer\n",
    "* dataset\n",
    "* trainer\n",
    "\n",
    "2) Create an EnergyTrainer object\n",
    "\n",
    "3) Train the model\n",
    "\n",
    "4) Validate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ba122e-4d44-405b-a50f-f33fa21c2534",
   "metadata": {
    "id": "kEPPcr0YYHpH"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d12c5b4-49b2-40b1-b25c-6f25a52c8cf6",
   "metadata": {
    "id": "d-0GsaGDW16G"
   },
   "outputs": [],
   "source": [
    "from ocpmodels.trainers import EnergyTrainer\n",
    "from ocpmodels.datasets import SinglePointLmdbDataset\n",
    "from ocpmodels import models\n",
    "from ocpmodels.common import logger\n",
    "from ocpmodels.common.utils import setup_logging\n",
    "setup_logging()\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3239cb3-b56b-40d5-9483-419ebfb2b04c",
   "metadata": {
    "id": "w20BJZ_GYWat"
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99cef08-5e5e-49ed-a91e-63da6e19ba79",
   "metadata": {
    "id": "BlL5gGPQW1te"
   },
   "outputs": [],
   "source": [
    "train_src = \"data/is2re/train_100/data.lmdb\"\n",
    "val_src = \"data/is2re/val_20/data.lmdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac60b61-3bfd-4f17-858c-253f66b30303",
   "metadata": {
    "id": "yT5qHT2wamPh"
   },
   "source": [
    "### Normalize data\n",
    "\n",
    "If you wish to normalize the targets we must compute the mean and standard deviation for our energy values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed770a-998e-49cd-9c68-00f2334d198a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vaY-ZUMaamPh",
    "outputId": "ec2a83f1-eb4c-443a-a2de-215c8286038a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3326: UserWarning: SinglePointLmdbDataset is deprecated and will be removed in the future.Please use 'LmdbDataset' instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SinglePointLmdbDataset({\"src\": train_src})\n",
    "\n",
    "energies = []\n",
    "for data in train_dataset:\n",
    "  energies.append(data.y_relaxed)\n",
    "\n",
    "mean = np.mean(energies)\n",
    "stdev = np.std(energies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169264bd-e5e1-4f90-824e-2ec493a231fc",
   "metadata": {
    "id": "K4SSW0UGYeYM"
   },
   "source": [
    "### Define the Config\n",
    "\n",
    "For this example, we will explicitly define the config; however, a set of default configs can be found [here](https://github.com/Open-Catalyst-Project/ocp/tree/master/configs). Default config yaml files can easily be loaded with the following [utility](https://github.com/Open-Catalyst-Project/ocp/blob/aa8e44d50229fce887b3a94a5661c4f85cd73eed/ocpmodels/common/utils.py#L361-L400). Loading a yaml config is preferrable when launching jobs from the command line. We have included our best models' config files here for reference. \n",
    "\n",
    "**Note** - we only train for a single epoch with a reduced batch size (GPU memory constraints) for demonstration purposes, modify accordingly for full convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bccc51-4204-4e5f-ae82-653e28e26fe0",
   "metadata": {
    "id": "TiHmkTm6W1do"
   },
   "outputs": [],
   "source": [
    "# Task\n",
    "task = {\n",
    "  \"dataset\": \"single_point_lmdb\",\n",
    "  \"description\": \"Relaxed state energy prediction from initial structure.\",\n",
    "  \"type\": \"regression\",\n",
    "  \"metric\": \"mae\",\n",
    "  \"labels\": [\"relaxed energy\"],\n",
    "}\n",
    "# Model\n",
    "model = {\n",
    "    'name': 'gemnet_t',\n",
    "    \"num_spherical\": 7,\n",
    "    \"num_radial\": 64,\n",
    "    \"num_blocks\": 5,\n",
    "    \"emb_size_atom\": 256,\n",
    "    \"emb_size_edge\": 512,\n",
    "    \"emb_size_trip\": 64,\n",
    "    \"emb_size_rbf\": 16,\n",
    "    \"emb_size_cbf\": 16,\n",
    "    \"emb_size_bil_trip\": 64,\n",
    "    \"num_before_skip\": 1,\n",
    "    \"num_after_skip\": 2,\n",
    "    \"num_concat\": 1,\n",
    "    \"num_atom\": 3,\n",
    "    \"cutoff\": 6.0,\n",
    "    \"max_neighbors\": 50,\n",
    "    \"rbf\": {\"name\": \"gaussian\"},\n",
    "    \"envelope\": {\n",
    "      \"name\": \"polynomial\",\n",
    "      \"exponent\": 5,\n",
    "    },\n",
    "    \"cbf\": {\"name\": \"spherical_harmonics\"},\n",
    "    \"extensive\": True,\n",
    "    \"otf_graph\": False,\n",
    "    \"output_init\": \"HeOrthogonal\",\n",
    "    \"activation\": \"silu\",\n",
    "    \"scale_file\": \"configs/s2ef/all/gemnet/scaling_factors/gemnet-dT.json\",\n",
    "    \"regress_forces\": False,\n",
    "    \"direct_forces\": False,\n",
    "}\n",
    "# Optimizer\n",
    "optimizer = {\n",
    "    'batch_size': 1,         # originally 32\n",
    "    'eval_batch_size': 1,    # originally 32\n",
    "    'num_workers': 2,\n",
    "    'lr_initial': 1.e-4,\n",
    "    'optimizer': 'AdamW',\n",
    "    'optimizer_params': {\"amsgrad\": True},\n",
    "    'scheduler': \"ReduceLROnPlateau\",\n",
    "    'mode': \"min\",\n",
    "    'factor': 0.8,\n",
    "    'patience': 3,\n",
    "    'max_epochs': 1,         # used for demonstration purposes\n",
    "    'ema_decay': 0.999,\n",
    "    'clip_grad_norm': 10,\n",
    "    'loss_energy': 'mae',\n",
    "}\n",
    "# Dataset\n",
    "dataset = [\n",
    "  {'src': train_src,\n",
    "   'normalize_labels': True,\n",
    "   'target_mean': mean,\n",
    "   'target_std': stdev,\n",
    "  }, # train set \n",
    "  {'src': val_src}, # val set (optional)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b458f0d5-11c1-47fd-9645-c77ddce2c185",
   "metadata": {
    "id": "oG5w1sk-v1LI"
   },
   "source": [
    "###Create EnergyTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63f53e2-bd3a-4a5f-b42c-a8b48d04cf47",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ExmkV2K1W07H",
    "outputId": "98e8408c-ec4d-461b-e50a-2fdc1a24bf16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amp: true\n",
      "cmd:\n",
      "  checkpoint_dir: ./checkpoints/2022-10-28-20-09-36-IS2RE-example\n",
      "  commit: 6e750b2\n",
      "  identifier: IS2RE-example\n",
      "  logs_dir: ./logs/tensorboard/2022-10-28-20-09-36-IS2RE-example\n",
      "  print_every: 5\n",
      "  results_dir: ./results/2022-10-28-20-09-36-IS2RE-example\n",
      "  seed: 0\n",
      "  timestamp_id: 2022-10-28-20-09-36-IS2RE-example\n",
      "dataset:\n",
      "  normalize_labels: true\n",
      "  src: data/is2re/train_100/data.lmdb\n",
      "  target_mean: !!python/object/apply:numpy.core.multiarray.scalar\n",
      "  - &id001 !!python/object/apply:numpy.dtype\n",
      "    args:\n",
      "    - f8\n",
      "    - false\n",
      "    - true\n",
      "    state: !!python/tuple\n",
      "    - 3\n",
      "    - <\n",
      "    - null\n",
      "    - null\n",
      "    - null\n",
      "    - -1\n",
      "    - -1\n",
      "    - 0\n",
      "  - !!binary |\n",
      "    MjyJzgpQ978=\n",
      "  target_std: !!python/object/apply:numpy.core.multiarray.scalar\n",
      "  - *id001\n",
      "  - !!binary |\n",
      "    PnyyzMtk/T8=\n",
      "gpus: 1\n",
      "logger: tensorboard\n",
      "model: gemnet_t\n",
      "model_attributes:\n",
      "  activation: silu\n",
      "  cbf:\n",
      "    name: spherical_harmonics\n",
      "  cutoff: 6.0\n",
      "  direct_forces: false\n",
      "  emb_size_atom: 256\n",
      "  emb_size_bil_trip: 64\n",
      "  emb_size_cbf: 16\n",
      "  emb_size_edge: 512\n",
      "  emb_size_rbf: 16\n",
      "  emb_size_trip: 64\n",
      "  envelope:\n",
      "    exponent: 5\n",
      "    name: polynomial\n",
      "  extensive: true\n",
      "  max_neighbors: 50\n",
      "  num_after_skip: 2\n",
      "  num_atom: 3\n",
      "  num_before_skip: 1\n",
      "  num_blocks: 5\n",
      "  num_concat: 1\n",
      "  num_radial: 64\n",
      "  num_spherical: 7\n",
      "  otf_graph: false\n",
      "  output_init: HeOrthogonal\n",
      "  rbf:\n",
      "    name: gaussian\n",
      "  regress_forces: false\n",
      "  scale_file: configs/s2ef/all/gemnet/scaling_factors/gemnet-dT.json\n",
      "noddp: false\n",
      "optim:\n",
      "  batch_size: 1\n",
      "  clip_grad_norm: 10\n",
      "  ema_decay: 0.999\n",
      "  eval_batch_size: 1\n",
      "  factor: 0.8\n",
      "  loss_energy: mae\n",
      "  lr_initial: 0.0001\n",
      "  max_epochs: 1\n",
      "  mode: min\n",
      "  num_workers: 2\n",
      "  optimizer: AdamW\n",
      "  optimizer_params:\n",
      "    amsgrad: true\n",
      "  patience: 3\n",
      "  scheduler: ReduceLROnPlateau\n",
      "slurm: {}\n",
      "task:\n",
      "  dataset: single_point_lmdb\n",
      "  description: Relaxed state energy prediction from initial structure.\n",
      "  labels:\n",
      "  - relaxed energy\n",
      "  metric: mae\n",
      "  type: regression\n",
      "trainer: energy\n",
      "val_dataset:\n",
      "  src: data/is2re/val_20/data.lmdb\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Scale factor OutBlock_0_had not found in model\n",
      "WARNING:root:Scale factor OutBlock_1_had not found in model\n",
      "WARNING:root:Scale factor OutBlock_2_had not found in model\n",
      "WARNING:root:Scale factor OutBlock_3_had not found in model\n",
      "WARNING:root:Model gradient logging to tensorboard not yet supported.\n"
     ]
    }
   ],
   "source": [
    "energy_trainer = EnergyTrainer(\n",
    "    task=task,\n",
    "    model=copy.deepcopy(model), # copied for later use, not necessary in practice.\n",
    "    dataset=dataset,\n",
    "    optimizer=optimizer,\n",
    "    identifier=\"IS2RE-example\",\n",
    "    run_dir=\"./\", # directory to save results if is_debug=False. Prediction files are saved here so be careful not to override!\n",
    "    is_debug=False, # if True, do not save checkpoint, logs, or results\n",
    "    print_every=5,\n",
    "    seed=0, # random seed to use\n",
    "    logger=\"tensorboard\", # logger of choice (tensorboard and wandb supported)\n",
    "    local_rank=0,\n",
    "    amp=True, # use PyTorch Automatic Mixed Precision (faster training and less memory usage)    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661e9599-bb94-45ed-9ffe-170064f6385b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tnJer5rGwjwi",
    "outputId": "fc4755a7-6cf8-4599-a164-a2fa3ac1b1e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OCPDataParallel(\n",
       "  (module): GemNetT(\n",
       "    (radial_basis): RadialBasis(\n",
       "      (envelope): PolynomialEnvelope()\n",
       "      (rbf): GaussianSmearing()\n",
       "    )\n",
       "    (cbf_basis3): CircularBasisLayer(\n",
       "      (radial_basis): RadialBasis(\n",
       "        (envelope): PolynomialEnvelope()\n",
       "        (rbf): GaussianSmearing()\n",
       "      )\n",
       "    )\n",
       "    (mlp_rbf3): Dense(\n",
       "      (linear): Linear(in_features=64, out_features=16, bias=False)\n",
       "      (_activation): Identity()\n",
       "    )\n",
       "    (mlp_cbf3): EfficientInteractionDownProjection()\n",
       "    (mlp_rbf_h): Dense(\n",
       "      (linear): Linear(in_features=64, out_features=16, bias=False)\n",
       "      (_activation): Identity()\n",
       "    )\n",
       "    (mlp_rbf_out): Dense(\n",
       "      (linear): Linear(in_features=64, out_features=16, bias=False)\n",
       "      (_activation): Identity()\n",
       "    )\n",
       "    (atom_emb): AtomEmbedding(\n",
       "      (embeddings): Embedding(83, 256)\n",
       "    )\n",
       "    (edge_emb): EdgeEmbedding(\n",
       "      (dense): Dense(\n",
       "        (linear): Linear(in_features=576, out_features=512, bias=False)\n",
       "        (_activation): ScaledSiLU(\n",
       "          (_activation): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (out_blocks): ModuleList(\n",
       "      (0): OutputBlock(\n",
       "        (dense_rbf): Dense(\n",
       "          (linear): Linear(in_features=16, out_features=512, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "        (scale_sum): ScaleFactor()\n",
       "        (layers): ModuleList(\n",
       "          (0): Dense(\n",
       "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (seq_energy): ModuleList(\n",
       "          (0): Dense(\n",
       "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_energy): Dense(\n",
       "          (linear): Linear(in_features=256, out_features=1, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): OutputBlock(\n",
       "        (dense_rbf): Dense(\n",
       "          (linear): Linear(in_features=16, out_features=512, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "        (scale_sum): ScaleFactor()\n",
       "        (layers): ModuleList(\n",
       "          (0): Dense(\n",
       "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (seq_energy): ModuleList(\n",
       "          (0): Dense(\n",
       "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_energy): Dense(\n",
       "          (linear): Linear(in_features=256, out_features=1, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): OutputBlock(\n",
       "        (dense_rbf): Dense(\n",
       "          (linear): Linear(in_features=16, out_features=512, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "        (scale_sum): ScaleFactor()\n",
       "        (layers): ModuleList(\n",
       "          (0): Dense(\n",
       "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (seq_energy): ModuleList(\n",
       "          (0): Dense(\n",
       "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_energy): Dense(\n",
       "          (linear): Linear(in_features=256, out_features=1, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): OutputBlock(\n",
       "        (dense_rbf): Dense(\n",
       "          (linear): Linear(in_features=16, out_features=512, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "        (scale_sum): ScaleFactor()\n",
       "        (layers): ModuleList(\n",
       "          (0): Dense(\n",
       "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (seq_energy): ModuleList(\n",
       "          (0): Dense(\n",
       "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_energy): Dense(\n",
       "          (linear): Linear(in_features=256, out_features=1, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): OutputBlock(\n",
       "        (dense_rbf): Dense(\n",
       "          (linear): Linear(in_features=16, out_features=512, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "        (scale_sum): ScaleFactor()\n",
       "        (layers): ModuleList(\n",
       "          (0): Dense(\n",
       "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (seq_energy): ModuleList(\n",
       "          (0): Dense(\n",
       "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_energy): Dense(\n",
       "          (linear): Linear(in_features=256, out_features=1, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): OutputBlock(\n",
       "        (dense_rbf): Dense(\n",
       "          (linear): Linear(in_features=16, out_features=512, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "        (scale_sum): ScaleFactor()\n",
       "        (layers): ModuleList(\n",
       "          (0): Dense(\n",
       "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (seq_energy): ModuleList(\n",
       "          (0): Dense(\n",
       "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (out_energy): Dense(\n",
       "          (linear): Linear(in_features=256, out_features=1, bias=False)\n",
       "          (_activation): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (int_blocks): ModuleList(\n",
       "      (0): InteractionBlockTripletsOnly(\n",
       "        (dense_ca): Dense(\n",
       "          (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (trip_interaction): TripletInteraction(\n",
       "          (dense_ba): Dense(\n",
       "            (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (mlp_rbf): Dense(\n",
       "            (linear): Linear(in_features=16, out_features=512, bias=False)\n",
       "            (_activation): Identity()\n",
       "          )\n",
       "          (scale_rbf): ScaleFactor()\n",
       "          (mlp_cbf): EfficientInteractionBilinear()\n",
       "          (scale_cbf_sum): ScaleFactor()\n",
       "          (down_projection): Dense(\n",
       "            (linear): Linear(in_features=512, out_features=64, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (up_projection_ca): Dense(\n",
       "            (linear): Linear(in_features=64, out_features=512, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (up_projection_ac): Dense(\n",
       "            (linear): Linear(in_features=64, out_features=512, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (layers_before_skip): ModuleList(\n",
       "          (0): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (layers_after_skip): ModuleList(\n",
       "          (0): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (atom_update): AtomUpdateBlock(\n",
       "          (dense_rbf): Dense(\n",
       "            (linear): Linear(in_features=16, out_features=512, bias=False)\n",
       "            (_activation): Identity()\n",
       "          )\n",
       "          (scale_sum): ScaleFactor()\n",
       "          (layers): ModuleList(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): ResidualLayer(\n",
       "              (dense_mlp): Sequential(\n",
       "                (0): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "                (1): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ResidualLayer(\n",
       "              (dense_mlp): Sequential(\n",
       "                (0): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "                (1): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): ResidualLayer(\n",
       "              (dense_mlp): Sequential(\n",
       "                (0): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "                (1): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (concat_layer): EdgeEmbedding(\n",
       "          (dense): Dense(\n",
       "            (linear): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (residual_m): ModuleList(\n",
       "          (0): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): InteractionBlockTripletsOnly(\n",
       "        (dense_ca): Dense(\n",
       "          (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (trip_interaction): TripletInteraction(\n",
       "          (dense_ba): Dense(\n",
       "            (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (mlp_rbf): Dense(\n",
       "            (linear): Linear(in_features=16, out_features=512, bias=False)\n",
       "            (_activation): Identity()\n",
       "          )\n",
       "          (scale_rbf): ScaleFactor()\n",
       "          (mlp_cbf): EfficientInteractionBilinear()\n",
       "          (scale_cbf_sum): ScaleFactor()\n",
       "          (down_projection): Dense(\n",
       "            (linear): Linear(in_features=512, out_features=64, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (up_projection_ca): Dense(\n",
       "            (linear): Linear(in_features=64, out_features=512, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (up_projection_ac): Dense(\n",
       "            (linear): Linear(in_features=64, out_features=512, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (layers_before_skip): ModuleList(\n",
       "          (0): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (layers_after_skip): ModuleList(\n",
       "          (0): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (atom_update): AtomUpdateBlock(\n",
       "          (dense_rbf): Dense(\n",
       "            (linear): Linear(in_features=16, out_features=512, bias=False)\n",
       "            (_activation): Identity()\n",
       "          )\n",
       "          (scale_sum): ScaleFactor()\n",
       "          (layers): ModuleList(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): ResidualLayer(\n",
       "              (dense_mlp): Sequential(\n",
       "                (0): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "                (1): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ResidualLayer(\n",
       "              (dense_mlp): Sequential(\n",
       "                (0): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "                (1): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): ResidualLayer(\n",
       "              (dense_mlp): Sequential(\n",
       "                (0): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "                (1): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (concat_layer): EdgeEmbedding(\n",
       "          (dense): Dense(\n",
       "            (linear): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (residual_m): ModuleList(\n",
       "          (0): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): InteractionBlockTripletsOnly(\n",
       "        (dense_ca): Dense(\n",
       "          (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (trip_interaction): TripletInteraction(\n",
       "          (dense_ba): Dense(\n",
       "            (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (mlp_rbf): Dense(\n",
       "            (linear): Linear(in_features=16, out_features=512, bias=False)\n",
       "            (_activation): Identity()\n",
       "          )\n",
       "          (scale_rbf): ScaleFactor()\n",
       "          (mlp_cbf): EfficientInteractionBilinear()\n",
       "          (scale_cbf_sum): ScaleFactor()\n",
       "          (down_projection): Dense(\n",
       "            (linear): Linear(in_features=512, out_features=64, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (up_projection_ca): Dense(\n",
       "            (linear): Linear(in_features=64, out_features=512, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (up_projection_ac): Dense(\n",
       "            (linear): Linear(in_features=64, out_features=512, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (layers_before_skip): ModuleList(\n",
       "          (0): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (layers_after_skip): ModuleList(\n",
       "          (0): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (atom_update): AtomUpdateBlock(\n",
       "          (dense_rbf): Dense(\n",
       "            (linear): Linear(in_features=16, out_features=512, bias=False)\n",
       "            (_activation): Identity()\n",
       "          )\n",
       "          (scale_sum): ScaleFactor()\n",
       "          (layers): ModuleList(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): ResidualLayer(\n",
       "              (dense_mlp): Sequential(\n",
       "                (0): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "                (1): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ResidualLayer(\n",
       "              (dense_mlp): Sequential(\n",
       "                (0): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "                (1): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): ResidualLayer(\n",
       "              (dense_mlp): Sequential(\n",
       "                (0): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "                (1): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (concat_layer): EdgeEmbedding(\n",
       "          (dense): Dense(\n",
       "            (linear): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (residual_m): ModuleList(\n",
       "          (0): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): InteractionBlockTripletsOnly(\n",
       "        (dense_ca): Dense(\n",
       "          (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (trip_interaction): TripletInteraction(\n",
       "          (dense_ba): Dense(\n",
       "            (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (mlp_rbf): Dense(\n",
       "            (linear): Linear(in_features=16, out_features=512, bias=False)\n",
       "            (_activation): Identity()\n",
       "          )\n",
       "          (scale_rbf): ScaleFactor()\n",
       "          (mlp_cbf): EfficientInteractionBilinear()\n",
       "          (scale_cbf_sum): ScaleFactor()\n",
       "          (down_projection): Dense(\n",
       "            (linear): Linear(in_features=512, out_features=64, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (up_projection_ca): Dense(\n",
       "            (linear): Linear(in_features=64, out_features=512, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (up_projection_ac): Dense(\n",
       "            (linear): Linear(in_features=64, out_features=512, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (layers_before_skip): ModuleList(\n",
       "          (0): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (layers_after_skip): ModuleList(\n",
       "          (0): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (atom_update): AtomUpdateBlock(\n",
       "          (dense_rbf): Dense(\n",
       "            (linear): Linear(in_features=16, out_features=512, bias=False)\n",
       "            (_activation): Identity()\n",
       "          )\n",
       "          (scale_sum): ScaleFactor()\n",
       "          (layers): ModuleList(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): ResidualLayer(\n",
       "              (dense_mlp): Sequential(\n",
       "                (0): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "                (1): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ResidualLayer(\n",
       "              (dense_mlp): Sequential(\n",
       "                (0): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "                (1): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): ResidualLayer(\n",
       "              (dense_mlp): Sequential(\n",
       "                (0): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "                (1): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (concat_layer): EdgeEmbedding(\n",
       "          (dense): Dense(\n",
       "            (linear): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (residual_m): ModuleList(\n",
       "          (0): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): InteractionBlockTripletsOnly(\n",
       "        (dense_ca): Dense(\n",
       "          (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (_activation): ScaledSiLU(\n",
       "            (_activation): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (trip_interaction): TripletInteraction(\n",
       "          (dense_ba): Dense(\n",
       "            (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (mlp_rbf): Dense(\n",
       "            (linear): Linear(in_features=16, out_features=512, bias=False)\n",
       "            (_activation): Identity()\n",
       "          )\n",
       "          (scale_rbf): ScaleFactor()\n",
       "          (mlp_cbf): EfficientInteractionBilinear()\n",
       "          (scale_cbf_sum): ScaleFactor()\n",
       "          (down_projection): Dense(\n",
       "            (linear): Linear(in_features=512, out_features=64, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (up_projection_ca): Dense(\n",
       "            (linear): Linear(in_features=64, out_features=512, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (up_projection_ac): Dense(\n",
       "            (linear): Linear(in_features=64, out_features=512, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (layers_before_skip): ModuleList(\n",
       "          (0): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (layers_after_skip): ModuleList(\n",
       "          (0): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (atom_update): AtomUpdateBlock(\n",
       "          (dense_rbf): Dense(\n",
       "            (linear): Linear(in_features=16, out_features=512, bias=False)\n",
       "            (_activation): Identity()\n",
       "          )\n",
       "          (scale_sum): ScaleFactor()\n",
       "          (layers): ModuleList(\n",
       "            (0): Dense(\n",
       "              (linear): Linear(in_features=512, out_features=256, bias=False)\n",
       "              (_activation): ScaledSiLU(\n",
       "                (_activation): SiLU()\n",
       "              )\n",
       "            )\n",
       "            (1): ResidualLayer(\n",
       "              (dense_mlp): Sequential(\n",
       "                (0): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "                (1): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ResidualLayer(\n",
       "              (dense_mlp): Sequential(\n",
       "                (0): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "                (1): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): ResidualLayer(\n",
       "              (dense_mlp): Sequential(\n",
       "                (0): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "                (1): Dense(\n",
       "                  (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "                  (_activation): ScaledSiLU(\n",
       "                    (_activation): SiLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (concat_layer): EdgeEmbedding(\n",
       "          (dense): Dense(\n",
       "            (linear): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (_activation): ScaledSiLU(\n",
       "              (_activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (residual_m): ModuleList(\n",
       "          (0): ResidualLayer(\n",
       "            (dense_mlp): Sequential(\n",
       "              (0): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Dense(\n",
       "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (_activation): ScaledSiLU(\n",
       "                  (_activation): SiLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_trainer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef4f9c2-ec91-44e1-8e47-5d5e427d535c",
   "metadata": {
    "id": "pto2SpJPwlz1"
   },
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666bb1b9-ecbf-4f0a-84a5-d043659bf82b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 869
    },
    "id": "iHMRkFplwsky",
    "outputId": "44955d60-2dab-4861-aa3d-2979a3a8ba68"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Scale factor OutBlock_4_sum (out_blocks.4.scale_sum) is not fitted. Please make sure that you either (1) load a checkpoint with fitted scale factors, (2) explicitly load scale factors using the `model.scale_file` attribute, or (3) fit the scale factors using the `fit.py` script.\n",
      "WARNING:root:Scale factor OutBlock_5_sum (out_blocks.5.scale_sum) is not fitted. Please make sure that you either (1) load a checkpoint with fitted scale factors, (2) explicitly load scale factors using the `model.scale_file` attribute, or (3) fit the scale factors using the `fit.py` script.\n",
      "WARNING:root:Scale factor TripInteraction_4_had_rbf (int_blocks.3.trip_interaction.scale_rbf) is not fitted. Please make sure that you either (1) load a checkpoint with fitted scale factors, (2) explicitly load scale factors using the `model.scale_file` attribute, or (3) fit the scale factors using the `fit.py` script.\n",
      "WARNING:root:Scale factor TripInteraction_4_sum_cbf (int_blocks.3.trip_interaction.scale_cbf_sum) is not fitted. Please make sure that you either (1) load a checkpoint with fitted scale factors, (2) explicitly load scale factors using the `model.scale_file` attribute, or (3) fit the scale factors using the `fit.py` script.\n",
      "WARNING:root:Scale factor AtomUpdate_4_sum (int_blocks.3.atom_update.scale_sum) is not fitted. Please make sure that you either (1) load a checkpoint with fitted scale factors, (2) explicitly load scale factors using the `model.scale_file` attribute, or (3) fit the scale factors using the `fit.py` script.\n",
      "WARNING:root:Scale factor TripInteraction_5_had_rbf (int_blocks.4.trip_interaction.scale_rbf) is not fitted. Please make sure that you either (1) load a checkpoint with fitted scale factors, (2) explicitly load scale factors using the `model.scale_file` attribute, or (3) fit the scale factors using the `fit.py` script.\n",
      "WARNING:root:Scale factor TripInteraction_5_sum_cbf (int_blocks.4.trip_interaction.scale_cbf_sum) is not fitted. Please make sure that you either (1) load a checkpoint with fitted scale factors, (2) explicitly load scale factors using the `model.scale_file` attribute, or (3) fit the scale factors using the `fit.py` script.\n",
      "WARNING:root:Scale factor AtomUpdate_5_sum (int_blocks.4.atom_update.scale_sum) is not fitted. Please make sure that you either (1) load a checkpoint with fitted scale factors, (2) explicitly load scale factors using the `model.scale_file` attribute, or (3) fit the scale factors using the `fit.py` script.\n",
      "/content/ocp/ocpmodels/models/gemnet/gemnet.py:373: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  neighbors_new // 2,\n",
      "/content/ocp/ocpmodels/models/gemnet/gemnet.py:467: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  block_sizes = neighbors // 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "energy_mae: 6.19e+01, energy_mse: 3.84e+03, energy_within_threshold: 0.00e+00, loss: 6.75e+01, lr: 1.00e-04, epoch: 5.00e-02, step: 5.00e+00\n",
      "energy_mae: 1.86e+02, energy_mse: 3.46e+04, energy_within_threshold: 0.00e+00, loss: 2.03e+02, lr: 1.00e-04, epoch: 1.00e-01, step: 1.00e+01\n",
      "energy_mae: 2.88e+03, energy_mse: 8.30e+06, energy_within_threshold: 0.00e+00, loss: 3.14e+03, lr: 1.00e-04, epoch: 1.50e-01, step: 1.50e+01\n",
      "energy_mae: 5.87e+02, energy_mse: 3.45e+05, energy_within_threshold: 0.00e+00, loss: 3.20e+02, lr: 1.00e-04, epoch: 2.00e-01, step: 2.00e+01\n",
      "energy_mae: 4.46e+03, energy_mse: 1.99e+07, energy_within_threshold: 0.00e+00, loss: 2.43e+03, lr: 1.00e-04, epoch: 2.50e-01, step: 2.50e+01\n",
      "energy_mae: 4.09e+01, energy_mse: 1.67e+03, energy_within_threshold: 0.00e+00, loss: 2.22e+01, lr: 1.00e-04, epoch: 3.00e-01, step: 3.00e+01\n",
      "energy_mae: 1.22e+02, energy_mse: 1.49e+04, energy_within_threshold: 0.00e+00, loss: 6.64e+01, lr: 1.00e-04, epoch: 3.50e-01, step: 3.50e+01\n",
      "energy_mae: 3.78e+01, energy_mse: 1.43e+03, energy_within_threshold: 0.00e+00, loss: 2.06e+01, lr: 1.00e-04, epoch: 4.00e-01, step: 4.00e+01\n",
      "energy_mae: 3.33e+02, energy_mse: 1.11e+05, energy_within_threshold: 0.00e+00, loss: 1.81e+02, lr: 1.00e-04, epoch: 4.50e-01, step: 4.50e+01\n",
      "energy_mae: 8.00e+00, energy_mse: 6.39e+01, energy_within_threshold: 0.00e+00, loss: 4.35e+00, lr: 1.00e-04, epoch: 5.00e-01, step: 5.00e+01\n",
      "energy_mae: 5.08e+01, energy_mse: 2.58e+03, energy_within_threshold: 0.00e+00, loss: 2.77e+01, lr: 1.00e-04, epoch: 5.50e-01, step: 5.50e+01\n",
      "energy_mae: 4.98e+01, energy_mse: 2.48e+03, energy_within_threshold: 0.00e+00, loss: 2.71e+01, lr: 1.00e-04, epoch: 6.00e-01, step: 6.00e+01\n",
      "energy_mae: 1.04e+03, energy_mse: 1.08e+06, energy_within_threshold: 0.00e+00, loss: 5.65e+02, lr: 1.00e-04, epoch: 6.50e-01, step: 6.50e+01\n",
      "energy_mae: 6.43e+03, energy_mse: 4.13e+07, energy_within_threshold: 0.00e+00, loss: 3.50e+03, lr: 1.00e-04, epoch: 7.00e-01, step: 7.00e+01\n",
      "energy_mae: 2.61e+01, energy_mse: 6.83e+02, energy_within_threshold: 0.00e+00, loss: 1.42e+01, lr: 1.00e-04, epoch: 7.50e-01, step: 7.50e+01\n",
      "energy_mae: 1.48e+02, energy_mse: 2.20e+04, energy_within_threshold: 0.00e+00, loss: 8.07e+01, lr: 1.00e-04, epoch: 8.00e-01, step: 8.00e+01\n",
      "energy_mae: 5.82e+00, energy_mse: 3.39e+01, energy_within_threshold: 0.00e+00, loss: 3.17e+00, lr: 1.00e-04, epoch: 8.50e-01, step: 8.50e+01\n",
      "energy_mae: 2.13e+02, energy_mse: 4.54e+04, energy_within_threshold: 0.00e+00, loss: 1.16e+02, lr: 1.00e-04, epoch: 9.00e-01, step: 9.00e+01\n",
      "energy_mae: 2.87e+02, energy_mse: 8.23e+04, energy_within_threshold: 0.00e+00, loss: 1.56e+02, lr: 1.00e-04, epoch: 9.50e-01, step: 9.50e+01\n",
      "energy_mae: 3.70e+02, energy_mse: 1.37e+05, energy_within_threshold: 0.00e+00, loss: 2.02e+02, lr: 1.00e-04, epoch: 1.00e+00, step: 1.00e+02\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-1376e0c2c410>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menergy_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/content/ocp/ocpmodels/trainers/energy_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, disable_eval_tqdm)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loader\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                         val_metrics = self.validate(\n\u001b[0m\u001b[1;32m    248\u001b[0m                             \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                             \u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_eval_tqdm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/ocp/ocpmodels/trainers/base_trainer.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, split, disable_tqdm)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0mensure_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrapped_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_master\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/ocp/ocpmodels/modules/scaling/util.py\u001b[0m in \u001b[0;36mensure_fitted\u001b[0;34m(module, warn)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: Scale factor OutBlock_4_sum (out_blocks.4.scale_sum) is not fitted. Please make sure that you either (1) load a checkpoint with fitted scale factors, (2) explicitly load scale factors using the `model.scale_file` attribute, or (3) fit the scale factors using the `fit.py` script."
     ]
    }
   ],
   "source": [
    "energy_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c17e47-f972-4466-b5de-29bcb31eaeb4",
   "metadata": {
    "id": "MkAd2MBmw8wO"
   },
   "source": [
    "### Validate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3150c89c-51b6-4fac-adcf-09edfc379efd",
   "metadata": {
    "id": "gaauxWdNw_-4"
   },
   "source": [
    "#### Load the best checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1081b9-5fad-4239-bbaa-9150e33f7e5f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xkj0Bslqws_N",
    "outputId": "1a880659-3333-47cd-cb20-fceea591af96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./checkpoints/2022-10-28-20-09-36-IS2RE-example/best_checkpoint.pt'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The `best_checpoint.pt` file contains the checkpoint with the best val performance\n",
    "checkpoint_path = os.path.join(energy_trainer.config[\"cmd\"][\"checkpoint_dir\"], \"best_checkpoint.pt\")\n",
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5464f6f-6265-4923-a0a3-7c34599e33ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BqmCqaFlbMZC",
    "outputId": "b59c0106-0b49-4c8f-fb00-6cd1264b7066"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'src': 'data/is2re/train_100/data.lmdb',\n",
       "  'normalize_labels': True,\n",
       "  'target_mean': -1.4570415561499996,\n",
       "  'target_std': 1.8371084209427546},\n",
       " {'src': 'data/is2re/val_20/data.lmdb'},\n",
       " {'src': 'data/is2re/val_20/data.lmdb'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the dataset with the test set. We use the same val set for demonstration.\n",
    "\n",
    "# Dataset\n",
    "dataset.append(\n",
    "  {'src': val_src}, # test set (optional)\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da86b4-75de-4c3c-a217-9a34430d365e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IkcqadZIxXP-",
    "outputId": "1065675e-4191-44a3-eaba-be3b6228b796"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amp: true\n",
      "cmd:\n",
      "  checkpoint_dir: ./checkpoints/2022-10-28-20-09-36-IS2RE-val-example\n",
      "  commit: 6e750b2\n",
      "  identifier: IS2RE-val-example\n",
      "  logs_dir: ./logs/tensorboard/2022-10-28-20-09-36-IS2RE-val-example\n",
      "  print_every: 10\n",
      "  results_dir: ./results/2022-10-28-20-09-36-IS2RE-val-example\n",
      "  seed: 0\n",
      "  timestamp_id: 2022-10-28-20-09-36-IS2RE-val-example\n",
      "dataset:\n",
      "  normalize_labels: true\n",
      "  src: data/is2re/train_100/data.lmdb\n",
      "  target_mean: !!python/object/apply:numpy.core.multiarray.scalar\n",
      "  - &id001 !!python/object/apply:numpy.dtype\n",
      "    args:\n",
      "    - f8\n",
      "    - false\n",
      "    - true\n",
      "    state: !!python/tuple\n",
      "    - 3\n",
      "    - <\n",
      "    - null\n",
      "    - null\n",
      "    - null\n",
      "    - -1\n",
      "    - -1\n",
      "    - 0\n",
      "  - !!binary |\n",
      "    MjyJzgpQ978=\n",
      "  target_std: !!python/object/apply:numpy.core.multiarray.scalar\n",
      "  - *id001\n",
      "  - !!binary |\n",
      "    PnyyzMtk/T8=\n",
      "gpus: 1\n",
      "logger: tensorboard\n",
      "model: gemnet_t\n",
      "model_attributes:\n",
      "  activation: silu\n",
      "  cbf:\n",
      "    name: spherical_harmonics\n",
      "  cutoff: 6.0\n",
      "  direct_forces: false\n",
      "  emb_size_atom: 256\n",
      "  emb_size_bil_trip: 64\n",
      "  emb_size_cbf: 16\n",
      "  emb_size_edge: 512\n",
      "  emb_size_rbf: 16\n",
      "  emb_size_trip: 64\n",
      "  envelope:\n",
      "    exponent: 5\n",
      "    name: polynomial\n",
      "  extensive: true\n",
      "  max_neighbors: 50\n",
      "  num_after_skip: 2\n",
      "  num_atom: 3\n",
      "  num_before_skip: 1\n",
      "  num_blocks: 5\n",
      "  num_concat: 1\n",
      "  num_radial: 64\n",
      "  num_spherical: 7\n",
      "  otf_graph: false\n",
      "  output_init: HeOrthogonal\n",
      "  rbf:\n",
      "    name: gaussian\n",
      "  regress_forces: false\n",
      "  scale_file: configs/s2ef/all/gemnet/scaling_factors/gemnet-dT.json\n",
      "noddp: false\n",
      "optim:\n",
      "  batch_size: 1\n",
      "  clip_grad_norm: 10\n",
      "  ema_decay: 0.999\n",
      "  eval_batch_size: 1\n",
      "  factor: 0.8\n",
      "  loss_energy: mae\n",
      "  lr_initial: 0.0001\n",
      "  max_epochs: 1\n",
      "  mode: min\n",
      "  num_workers: 2\n",
      "  optimizer: AdamW\n",
      "  optimizer_params:\n",
      "    amsgrad: true\n",
      "  patience: 3\n",
      "  scheduler: ReduceLROnPlateau\n",
      "slurm: {}\n",
      "task:\n",
      "  dataset: single_point_lmdb\n",
      "  description: Relaxed state energy prediction from initial structure.\n",
      "  labels:\n",
      "  - relaxed energy\n",
      "  metric: mae\n",
      "  type: regression\n",
      "test_dataset:\n",
      "  src: data/is2re/val_20/data.lmdb\n",
      "trainer: energy\n",
      "val_dataset:\n",
      "  src: data/is2re/val_20/data.lmdb\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Scale factor OutBlock_0_had not found in model\n",
      "WARNING:root:Scale factor OutBlock_1_had not found in model\n",
      "WARNING:root:Scale factor OutBlock_2_had not found in model\n",
      "WARNING:root:Scale factor OutBlock_3_had not found in model\n",
      "WARNING:root:Model gradient logging to tensorboard not yet supported.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-288ecbf0723c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mpretrained_energy_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/content/ocp/ocpmodels/trainers/base_trainer.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(self, checkpoint_path)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             raise FileNotFoundError(\n\u001b[0m\u001b[1;32m    402\u001b[0m                 \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Checkpoint file not found\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Checkpoint file not found: './checkpoints/2022-10-28-20-09-36-IS2RE-example/best_checkpoint.pt'"
     ]
    }
   ],
   "source": [
    "pretrained_energy_trainer = EnergyTrainer(\n",
    "    task=task,\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    optimizer=optimizer,\n",
    "    identifier=\"IS2RE-val-example\",\n",
    "    run_dir=\"./\", # directory to save results if is_debug=False. Prediction files are saved here so be careful not to override!\n",
    "    is_debug=False, # if True, do not save checkpoint, logs, or results\n",
    "    print_every=10,\n",
    "    seed=0, # random seed to use\n",
    "    logger=\"tensorboard\", # logger of choice (tensorboard and wandb supported)\n",
    "    local_rank=0,\n",
    "    amp=True, # use PyTorch Automatic Mixed Precision (faster training and less memory usage)\n",
    ")\n",
    "\n",
    "pretrained_energy_trainer.load_checkpoint(checkpoint_path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55ecce8-3605-4fbb-bd36-6aa32d0698d6",
   "metadata": {
    "id": "TcUvAI81xoSt"
   },
   "source": [
    "#### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578bf58e-5b2b-40b7-90d5-ab5b6774290a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "VtCEFtXxxr3u",
    "outputId": "ee921fdd-a12a-4364-f182-2df48b318310"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-705daa89b864>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# make predictions on the existing test_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_energy_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"is2re_results\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/ocp/ocpmodels/trainers/energy_trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, loader, per_image, results_file, disable_tqdm)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     ):\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mensure_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrapped_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_master\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/ocp/ocpmodels/modules/scaling/util.py\u001b[0m in \u001b[0;36mensure_fitted\u001b[0;34m(module, warn)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: Scale factor OutBlock_4_sum (out_blocks.4.scale_sum) is not fitted. Please make sure that you either (1) load a checkpoint with fitted scale factors, (2) explicitly load scale factors using the `model.scale_file` attribute, or (3) fit the scale factors using the `fit.py` script."
     ]
    }
   ],
   "source": [
    "# make predictions on the existing test_loader\n",
    "predictions = pretrained_energy_trainer.predict(pretrained_trainer.test_loader, results_file=\"is2re_results\", disable_tqdm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118ff20c-2e32-4c4a-8d8b-9aea0f9d4879",
   "metadata": {
    "id": "1UcfxFi4x4aD"
   },
   "outputs": [],
   "source": [
    "energies = predictions[\"energy\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
