Traceback (most recent call last):
  File "/home/runner/micromamba-root/envs/buildenv/lib/python3.9/site-packages/jupyter_cache/executors/utils.py", line 51, in single_nb_execution
    executenb(
  File "/home/runner/micromamba-root/envs/buildenv/lib/python3.9/site-packages/nbclient/client.py", line 1204, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/home/runner/micromamba-root/envs/buildenv/lib/python3.9/site-packages/nbclient/util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/home/runner/micromamba-root/envs/buildenv/lib/python3.9/site-packages/nbclient/util.py", line 62, in just_run
    return loop.run_until_complete(coro)
  File "/home/runner/micromamba-root/envs/buildenv/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/runner/micromamba-root/envs/buildenv/lib/python3.9/site-packages/nbclient/client.py", line 663, in async_execute
    await self.async_execute_cell(
  File "/home/runner/micromamba-root/envs/buildenv/lib/python3.9/site-packages/nbclient/client.py", line 965, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/home/runner/micromamba-root/envs/buildenv/lib/python3.9/site-packages/nbclient/client.py", line 862, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
trainer = ForcesTrainer(
    task=task,
    model=model,
    dataset=dataset,
    optimizer=optimizer,
    identifier="is2rs-example",
    run_dir="./", # directory to save results if is_debug=False. Prediction files are saved here so be careful not to override!
    is_debug=False, # if True, do not save checkpoint, logs, or results
    print_every=5,
    seed=0, # random seed to use
    logger="tensorboard", # logger of choice (tensorboard and wandb supported)
    local_rank=0,
    amp=True, # use PyTorch Automatic Mixed Precision (faster training and less memory usage)
)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mAssertionError[0m                            Traceback (most recent call last)
Cell [0;32mIn [5], line 1[0m
[0;32m----> 1[0m trainer [38;5;241m=[39m [43mForcesTrainer[49m[43m([49m
[1;32m      2[0m [43m    [49m[43mtask[49m[38;5;241;43m=[39;49m[43mtask[49m[43m,[49m
[1;32m      3[0m [43m    [49m[43mmodel[49m[38;5;241;43m=[39;49m[43mmodel[49m[43m,[49m
[1;32m      4[0m [43m    [49m[43mdataset[49m[38;5;241;43m=[39;49m[43mdataset[49m[43m,[49m
[1;32m      5[0m [43m    [49m[43moptimizer[49m[38;5;241;43m=[39;49m[43moptimizer[49m[43m,[49m
[1;32m      6[0m [43m    [49m[43midentifier[49m[38;5;241;43m=[39;49m[38;5;124;43m"[39;49m[38;5;124;43mis2rs-example[39;49m[38;5;124;43m"[39;49m[43m,[49m
[1;32m      7[0m [43m    [49m[43mrun_dir[49m[38;5;241;43m=[39;49m[38;5;124;43m"[39;49m[38;5;124;43m./[39;49m[38;5;124;43m"[39;49m[43m,[49m[43m [49m[38;5;66;43;03m# directory to save results if is_debug=False. Prediction files are saved here so be careful not to override![39;49;00m
[1;32m      8[0m [43m    [49m[43mis_debug[49m[38;5;241;43m=[39;49m[38;5;28;43;01mFalse[39;49;00m[43m,[49m[43m [49m[38;5;66;43;03m# if True, do not save checkpoint, logs, or results[39;49;00m
[1;32m      9[0m [43m    [49m[43mprint_every[49m[38;5;241;43m=[39;49m[38;5;241;43m5[39;49m[43m,[49m
[1;32m     10[0m [43m    [49m[43mseed[49m[38;5;241;43m=[39;49m[38;5;241;43m0[39;49m[43m,[49m[43m [49m[38;5;66;43;03m# random seed to use[39;49;00m
[1;32m     11[0m [43m    [49m[43mlogger[49m[38;5;241;43m=[39;49m[38;5;124;43m"[39;49m[38;5;124;43mtensorboard[39;49m[38;5;124;43m"[39;49m[43m,[49m[43m [49m[38;5;66;43;03m# logger of choice (tensorboard and wandb supported)[39;49;00m
[1;32m     12[0m [43m    [49m[43mlocal_rank[49m[38;5;241;43m=[39;49m[38;5;241;43m0[39;49m[43m,[49m
[1;32m     13[0m [43m    [49m[43mamp[49m[38;5;241;43m=[39;49m[38;5;28;43;01mTrue[39;49;00m[43m,[49m[43m [49m[38;5;66;43;03m# use PyTorch Automatic Mixed Precision (faster training and less memory usage)[39;49;00m
[1;32m     14[0m [43m)[49m

File [0;32m~/work/ml_catalysis_tutorials/ml_catalysis_tutorials/ocp/ocpmodels/trainers/forces_trainer.py:88[0m, in [0;36mForcesTrainer.__init__[0;34m(self, task, model, dataset, optimizer, identifier, normalizer, timestamp_id, run_dir, is_debug, is_hpo, print_every, seed, logger, local_rank, amp, cpu, slurm, noddp)[0m
[1;32m     67[0m [38;5;28;01mdef[39;00m [38;5;21m__init__[39m(
[1;32m     68[0m     [38;5;28mself[39m,
[1;32m     69[0m     task,
[0;32m   (...)[0m
[1;32m     86[0m     noddp[38;5;241m=[39m[38;5;28;01mFalse[39;00m,
[1;32m     87[0m ):
[0;32m---> 88[0m     [38;5;28;43msuper[39;49m[43m([49m[43m)[49m[38;5;241;43m.[39;49m[38;5;21;43m__init__[39;49m[43m([49m
[1;32m     89[0m [43m        [49m[43mtask[49m[38;5;241;43m=[39;49m[43mtask[49m[43m,[49m
[1;32m     90[0m [43m        [49m[43mmodel[49m[38;5;241;43m=[39;49m[43mmodel[49m[43m,[49m
[1;32m     91[0m [43m        [49m[43mdataset[49m[38;5;241;43m=[39;49m[43mdataset[49m[43m,[49m
[1;32m     92[0m [43m        [49m[43moptimizer[49m[38;5;241;43m=[39;49m[43moptimizer[49m[43m,[49m
[1;32m     93[0m [43m        [49m[43midentifier[49m[38;5;241;43m=[39;49m[43midentifier[49m[43m,[49m
[1;32m     94[0m [43m        [49m[43mnormalizer[49m[38;5;241;43m=[39;49m[43mnormalizer[49m[43m,[49m
[1;32m     95[0m [43m        [49m[43mtimestamp_id[49m[38;5;241;43m=[39;49m[43mtimestamp_id[49m[43m,[49m
[1;32m     96[0m [43m        [49m[43mrun_dir[49m[38;5;241;43m=[39;49m[43mrun_dir[49m[43m,[49m
[1;32m     97[0m [43m        [49m[43mis_debug[49m[38;5;241;43m=[39;49m[43mis_debug[49m[43m,[49m
[1;32m     98[0m [43m        [49m[43mis_hpo[49m[38;5;241;43m=[39;49m[43mis_hpo[49m[43m,[49m
[1;32m     99[0m [43m        [49m[43mprint_every[49m[38;5;241;43m=[39;49m[43mprint_every[49m[43m,[49m
[1;32m    100[0m [43m        [49m[43mseed[49m[38;5;241;43m=[39;49m[43mseed[49m[43m,[49m
[1;32m    101[0m [43m        [49m[43mlogger[49m[38;5;241;43m=[39;49m[43mlogger[49m[43m,[49m
[1;32m    102[0m [43m        [49m[43mlocal_rank[49m[38;5;241;43m=[39;49m[43mlocal_rank[49m[43m,[49m
[1;32m    103[0m [43m        [49m[43mamp[49m[38;5;241;43m=[39;49m[43mamp[49m[43m,[49m
[1;32m    104[0m [43m        [49m[43mcpu[49m[38;5;241;43m=[39;49m[43mcpu[49m[43m,[49m
[1;32m    105[0m [43m        [49m[43mname[49m[38;5;241;43m=[39;49m[38;5;124;43m"[39;49m[38;5;124;43ms2ef[39;49m[38;5;124;43m"[39;49m[43m,[49m
[1;32m    106[0m [43m        [49m[43mslurm[49m[38;5;241;43m=[39;49m[43mslurm[49m[43m,[49m
[1;32m    107[0m [43m        [49m[43mnoddp[49m[38;5;241;43m=[39;49m[43mnoddp[49m[43m,[49m
[1;32m    108[0m [43m    [49m[43m)[49m

File [0;32m~/work/ml_catalysis_tutorials/ml_catalysis_tutorials/ocp/ocpmodels/trainers/base_trainer.py:205[0m, in [0;36mBaseTrainer.__init__[0;34m(self, task, model, dataset, optimizer, identifier, normalizer, timestamp_id, run_dir, is_debug, is_hpo, print_every, seed, logger, local_rank, amp, cpu, name, slurm, noddp)[0m
[1;32m    203[0m [38;5;28;01mif[39;00m distutils[38;5;241m.[39mis_master():
[1;32m    204[0m     [38;5;28mprint[39m(yaml[38;5;241m.[39mdump([38;5;28mself[39m[38;5;241m.[39mconfig, default_flow_style[38;5;241m=[39m[38;5;28;01mFalse[39;00m))
[0;32m--> 205[0m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mload[49m[43m([49m[43m)[49m
[1;32m    207[0m [38;5;28mself[39m[38;5;241m.[39mevaluator [38;5;241m=[39m Evaluator(task[38;5;241m=[39mname)

File [0;32m~/work/ml_catalysis_tutorials/ml_catalysis_tutorials/ocp/ocpmodels/trainers/base_trainer.py:212[0m, in [0;36mBaseTrainer.load[0;34m(self)[0m
[1;32m    210[0m [38;5;28mself[39m[38;5;241m.[39mload_seed_from_config()
[1;32m    211[0m [38;5;28mself[39m[38;5;241m.[39mload_logger()
[0;32m--> 212[0m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mload_datasets[49m[43m([49m[43m)[49m
[1;32m    213[0m [38;5;28mself[39m[38;5;241m.[39mload_task()
[1;32m    214[0m [38;5;28mself[39m[38;5;241m.[39mload_model()

File [0;32m~/work/ml_catalysis_tutorials/ml_catalysis_tutorials/ocp/ocpmodels/trainers/base_trainer.py:290[0m, in [0;36mBaseTrainer.load_datasets[0;34m(self)[0m
[1;32m    287[0m [38;5;28mself[39m[38;5;241m.[39mtrain_loader [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mval_loader [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mtest_loader [38;5;241m=[39m [38;5;28;01mNone[39;00m
[1;32m    289[0m [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mconfig[38;5;241m.[39mget([38;5;124m"[39m[38;5;124mdataset[39m[38;5;124m"[39m, [38;5;28;01mNone[39;00m):
[0;32m--> 290[0m     [38;5;28mself[39m[38;5;241m.[39mtrain_dataset [38;5;241m=[39m [43mregistry[49m[38;5;241;43m.[39;49m[43mget_dataset_class[49m[43m([49m
[1;32m    291[0m [43m        [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mconfig[49m[43m[[49m[38;5;124;43m"[39;49m[38;5;124;43mtask[39;49m[38;5;124;43m"[39;49m[43m][49m[43m[[49m[38;5;124;43m"[39;49m[38;5;124;43mdataset[39;49m[38;5;124;43m"[39;49m[43m][49m
[1;32m    292[0m [43m    [49m[43m)[49m[43m([49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mconfig[49m[43m[[49m[38;5;124;43m"[39;49m[38;5;124;43mdataset[39;49m[38;5;124;43m"[39;49m[43m][49m[43m)[49m
[1;32m    293[0m     [38;5;28mself[39m[38;5;241m.[39mtrain_sampler [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mget_sampler(
[1;32m    294[0m         [38;5;28mself[39m[38;5;241m.[39mtrain_dataset,
[1;32m    295[0m         [38;5;28mself[39m[38;5;241m.[39mconfig[[38;5;124m"[39m[38;5;124moptim[39m[38;5;124m"[39m][[38;5;124m"[39m[38;5;124mbatch_size[39m[38;5;124m"[39m],
[1;32m    296[0m         shuffle[38;5;241m=[39m[38;5;28;01mTrue[39;00m,
[1;32m    297[0m     )
[1;32m    298[0m     [38;5;28mself[39m[38;5;241m.[39mtrain_loader [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mget_dataloader(
[1;32m    299[0m         [38;5;28mself[39m[38;5;241m.[39mtrain_dataset,
[1;32m    300[0m         [38;5;28mself[39m[38;5;241m.[39mtrain_sampler,
[1;32m    301[0m     )

File [0;32m~/work/ml_catalysis_tutorials/ml_catalysis_tutorials/ocp/ocpmodels/datasets/lmdb_dataset.py:50[0m, in [0;36mLmdbDataset.__init__[0;34m(self, config, transform)[0m
[1;32m     48[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m [38;5;28mself[39m[38;5;241m.[39mpath[38;5;241m.[39mis_file():
[1;32m     49[0m     db_paths [38;5;241m=[39m [38;5;28msorted[39m([38;5;28mself[39m[38;5;241m.[39mpath[38;5;241m.[39mglob([38;5;124m"[39m[38;5;124m*.lmdb[39m[38;5;124m"[39m))
[0;32m---> 50[0m     [38;5;28;01massert[39;00m [38;5;28mlen[39m(db_paths) [38;5;241m>[39m [38;5;241m0[39m, [38;5;124mf[39m[38;5;124m"[39m[38;5;124mNo LMDBs found in [39m[38;5;124m'[39m[38;5;132;01m{[39;00m[38;5;28mself[39m[38;5;241m.[39mpath[38;5;132;01m}[39;00m[38;5;124m'[39m[38;5;124m"[39m
[1;32m     52[0m     [38;5;28mself[39m[38;5;241m.[39mmetadata_path [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mpath [38;5;241m/[39m [38;5;124m"[39m[38;5;124mmetadata.npz[39m[38;5;124m"[39m
[1;32m     54[0m     [38;5;28mself[39m[38;5;241m.[39m_keys, [38;5;28mself[39m[38;5;241m.[39menvs [38;5;241m=[39m [], []

[0;31mAssertionError[0m: No LMDBs found in 'data/s2ef/train_100'
AssertionError: No LMDBs found in 'data/s2ef/train_100'

